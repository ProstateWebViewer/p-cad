<template name="ohifViewer">
    {{#header brandHref='http://prostatecancer.ai' headerClasses=instance.headerClasses}}
        {{#section 'brand'}}
            <div class="logo-text">ProstateCancer.ai</div>
        {{/section}}
        {{#section 'headerAfterBrand'}}
            {{#if studyListToggleText}}
                <a href="#" class="btn studyListLinkSection pull-left js-toggle-studyList">
                    {{studyListToggleText}}
                </a>
            {{/if}}
        {{/section}}
        {{#section 'headerMenu'}}
            <span class="user-name pull-left m-r-1">{{userName}}</span>
            <span class="header-options pull-left m-r-1"> | </span>
            <span class="header-options pull-left m-r-1">Options</span>
            <div class="menu-toggle pull-right">
                <span class="caret-down"></span>
            </div>
        {{/section}}
    {{/header}}
    {{#if inStudyList}}
        <br>
        <div id="how-to">
            <div id="how-to-content">
                <br>
                <p>
                  ProstateCancer.ai is an open-source web-application, developed on
                  Tesseract-MedicalImaging platform, to enable a second opinion for
                  radiologists with the help of AI, while simultaneously provide standard
                  image viewing and reporting scheme.
                  <br><br>
                  For each case, the application presents 4 separate MR image stacks
                  of T2-weighted images, ADC map, high b-value DWI, and Ktrans map obtained
                  from contrast-enhanced imaging. The first time that the user selects the
                  AI probe, he/she will be directed to the AI setting to choose the desired
                  model from the list of all available models along with their descriptions.
                  Next, the user can put the probe at any location on images to view the result
                  of the AI prediction. The user can confirm or dismiss a finding after inspecting
                  the AI prediction. Next, the user will be directed to the interface for
                  reporting using PI-RADS v2. After entering the finding anatomical, and scores
                  for each image, the user may submit the report. After submission, the application
                  gives the user a feedback message projection of the results on the 4 image views
                  and histologically proven outcomes. Relative distances (in mm) between user-defined
                  findings and the biopsy locations are also calculated and displayed to the user.
                </p>
                <br>
            </div>
        </div>
        <br>
    {{/if}}
    {{>Template.dynamic template=(choose this.template 'studylist') data=this}}
</template>
